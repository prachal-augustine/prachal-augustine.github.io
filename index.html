<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Prachal Augustine | Data Engineer Portfolio</title>
    <style>
        :root { --primary: #003366; --accent: #007bff; --text: #333; --bg: #f8f9fa; }
        body { font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif; line-height: 1.6; color: var(--text); background-color: var(--bg); margin: 0; padding: 0; }
        .container { max-width: 900px; margin: 40px auto; background: #fff; padding: 50px; box-shadow: 0 0 20px rgba(0,0,0,0.1); border-radius: 4px; }
        header { text-align: center; border-bottom: 3px solid var(--primary); padding-bottom: 20px; }
        h1 { margin: 0; font-size: 2.5em; color: var(--primary); letter-spacing: 1px; }
        .contact-details { margin-top: 15px; font-size: 0.95em; color: #555; }
        .section-header { background: #f0f4f8; padding: 10px 15px; border-left: 6px solid var(--primary); font-weight: bold; text-transform: uppercase; margin: 35px 0 15px 0; font-size: 1.1em; }
        .job-header { display: flex; justify-content: space-between; font-weight: bold; color: var(--primary); margin-top: 20px; }
        .project-title { font-weight: bold; color: #444; margin-top: 12px; display: block; border-bottom: 1px solid #eee; }
        .cert-badge { display: block; background: #e7f3ff; border: 1px solid #b3d7ff; padding: 10px; border-radius: 4px; margin-bottom: 10px; color: #004085; font-weight: 500; }
        .skills-group { margin-bottom: 15px; }
        .skills-group b { color: var(--primary); }
        ul { margin-top: 8px; }
        li { margin-bottom: 6px; }
        @media (max-width: 600px) { .container { padding: 20px; margin: 10px; } .job-header { flex-direction: column; } }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>PRACHAL AUGUSTINE</h1>
            <div class="contact-details">
                Haveli Darvaja, Mahoba, Uttar Pradesh 210427<br>
                (+91)-6360703302 | (+91)-8299324771<br>
                <a href="mailto:prachalaugustine@outlook.com">prachalaugustine@outlook.com</a> | 
                <a href="https://WWW.LINKEDIN.COM/IN/PRACHAL" target="_blank">LinkedIn</a>
            </div>
        </header>

        <div class="section-header">Objective</div>
        <p>Data Engineer with 5 years of experience in designing scalable data pipelines and ETL, proficient in Python, PySpark, SQL, AWS(S3), Databricks, and Kafka. Seeking to leverage my expertise in data processing, ingestion, and transformation to contribute to a dynamic organization's growth while advancing my professional development.</p>

        <div class="section-header">Technologies and Skills</div>
        <div class="skills-group"><b>Core Skills:</b> Data Engineering, ETL (Extract, Transform, Load), Data Pipelines, Data Warehousing, Data Ingestion, Data Transformation, Data Processing, Big Data, Data Orchestration, Cloud.</div>
        <div class="skills-group"><b>Tools & Tech:</b> Python, Pyspark, Apache Spark, SQL, Kafka, AWS(S3), HDFS, Unix, Iceberg, Databricks, Oracle Database, GIT, Informatica Powercenter.</div>

        <div class="section-header">Certificates</div>
        <div class="cert-badge">üèÜ Databricks Certified Associate Developer for Apache Spark 3.0</div>
        <div class="cert-badge">üèÜ Databricks Certified Data Engineer Associate</div>

        <div class="section-header">Work Experience</div>

        <div class="job-header">
            <span>Consultant | KPMG</span>
            <span>Dec 2021 - Present</span>
        </div>
        <span class="project-title">Project: US Deposits, Goldman Sachs</span>
        <ul>
            <li>Proficiently designed and implemented scalable data pipelines using PySpark and Python, efficiently integrating AWS(S3) Bucket with an in-house data orchestration platform to streamline data ingestion and processing workflows.</li>
            <li>Developed and managed a robust data ingestion framework for transforming and populating data into S3 bucket & Snowflake data warehouse, operational data store (ODS), which was pivotal for generating comprehensive financial reports and tracking KPIs.</li>
            <li>Worked with diverse data sources such as Kafka, CSV, Parquet, Iceberg, and Oracle Database while demonstrating proficiency in managing sensitive PII (Personally Identifiable Information) data.</li>
            <li>Led the migration of legacy Informatica on-prem data flows to a cloud-native architecture by reimplementing transformations in PySpark and Python, enabling improved scalability and performance.</li>
        </ul>

        <div class="job-header">
            <span>Associate Consultant | Capgemini</span>
            <span>Jun 2019 - Dec 2021</span>
        </div>
        <span class="project-title">Project: Product Profitability, Vertiv</span>
        <ul>
            <li>Built an end-to-end ETL pipeline in DataZap (ETL Tool), Hadoop to extract data from various sources like Oracle ERP, SAP, Oracle BI, and Oracle Fusion to ingest data in Data Lake.</li>
            <li>Designed complex ETL queries and objects to obtain revenue and customer-related information across regions and products to aid business decisions.</li>
            <li>Developed Python scripts for file manipulation to reduce the manual efforts of file loads by 40%.</li>
            <li>Responsible for all project migration activities and deployed ETL objects to production.</li>
            <li>Worked along with Business Analysts to define business logic and provided the technical solution for the same.</li>
        </ul>

        <span class="project-title">Project: Marketing Dashboard, Vertiv</span>
        <ul>
            <li>Designed efficient python codes to extract data from Rest APIs like Google Ads, LinkedIn, Qualtrics and Bananatag which helped Business users to analyze marketing and advertisement performance.</li>
            <li>Directly communicated with the client to gather and understand business requirements and delivered quality solutions accordingly.</li>
            <li>Designed shell scripts to facilitate ETL load into Data Lake by using HDFS.</li>
        </ul>

        <span class="project-title">Project: Analytics, Grant Thornton</span>
        <ul>
            <li>Designed ETL mappings and workflows in Informatica Powercenter.</li>
            <li>Actively worked on change requests and resolved the incidents within the SLA.</li>
            <li>Designed technical documentation for developed ETL pipelines.</li>
        </ul>

        <span class="project-title">Project: EDWM, Telia</span>
        <ul>
            <li>Designed SQL queries and objects in SQL Server for Data Warehousing activities.</li>
            <li>Investigated incidents and technical issues addressed by clients and resolved them within the SLA.</li>
            <li>Assisted the development team by analyzing and providing them the information on existing KPIs data flow to accelerate the development activity.</li>
        </ul>

        <div class="section-header">Education</div>
        <ul>
            <li><b>B.E. in IT</b> - Technocrats Institute of Technology, May 2019 (CGPA: 8.45)</li>
            <li><b>12th Grade</b> - St. Joseph English Medium School (Percentage: 71.2%)</li>
            <li><b>10th Grade</b> - St. Joseph English Medium School (Percentage: 81.7%)</li>
        </ul>
    </div>
</body>
</html>
